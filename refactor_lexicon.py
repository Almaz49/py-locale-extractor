#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
py-locale-extractor ‚Äî –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∫ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
–≤ —Å–ª–æ–≤–∞—Ä—å –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ (LEXICON) –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö –Ω–∞ aiogram.

–ê–≤—Ç–æ—Ä: Almaz49
–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/Almaz49/py-locale-extractor
"""

# üí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: —Å–∫—Ä–∏–ø—Ç –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç, —á—Ç–æ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è:
#     get_text(key: str, lang: str) -> str
# –∏ —á—Ç–æ –≤ —Ö—ç–Ω–¥–ª–µ—Ä–∞—Ö –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è `lang` (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ FSM –∏–ª–∏ middleware).


import os
import re
import shutil
from typing import Set, Dict, List, Optional, Tuple

# -----------------------------
# -----------------------------
# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò ‚Äî –∏–∑–º–µ–Ω–∏—Ç–µ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º!
# -----------------------------
INPUT_FILE = "handlers/your_handler.py"        # —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
START_LINE = 1                                 # —Å –∫–∞–∫–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—Ç—å (1 = —Å –Ω–∞—á–∞–ª–∞)
LEXICON_OUTPUT_FILE = "LEXICON_RU.auto.py"     # –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–ª–æ–≤–∞—Ä—å
# -----------------------------

BASENAME = os.path.basename(INPUT_FILE)
MODULE_PREFIX = BASENAME.replace("_handlers.py", "").replace(".py", "") or "global"
BACKUP_FILE = INPUT_FILE + ".bak"

# –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–ª–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–ª—é—á–µ–π
RU_TO_EN = {
    "–¥–∞": "yes",
    "–Ω–µ—Ç": "no",
    "–ø—Ä–∏–≤–µ—Ç": "hello",
    "–ø–æ–∫–∞": "goodbye",
    "—Å–æ–æ–±—â–µ–Ω–∏–µ": "message",
    "–≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ": "voting",
    "–Ω–∞–∑–≤–∞–Ω–∏–µ": "title",
    "–æ–ø–∏—Å–∞–Ω–∏–µ": "description",
    "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å": "confirm",
    "–æ—Ç–º–µ–Ω–∞": "cancel",
    # ... –¥–æ–±–∞–≤—å—Ç–µ –µ—â—ë –ø–æ –∂–µ–ª–∞–Ω–∏—é
}


SEND_FUNCTIONS = {
    "answer", "send_message", "reply", "edit_text",
    "send_photo", "send_document", "send_animation"
}

generated_keys: Set[str] = set()

def translate_word(word: str) -> str:
    word_clean = word.lower().strip(".,;:!?\"'")
    if word_clean in RU_TO_EN:
        return RU_TO_EN[word_clean]
    if word.isdigit():
        return word
    translit_map = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch',
        '—ã': 'y', '—ç': 'e', '—é': 'yu', '—è': 'ya'
    }
    result = ""
    for ch in word_clean:
        if ch in translit_map:
            result += translit_map[ch]
        elif ch.isalnum():
            result += ch
    return result or "value"

def smart_slugify(text: str) -> str:
    # –£–±–∏—Ä–∞–µ–º —Ñ–æ—Ä–º–∞—Ç-–ø–æ–ª—è –≤—Ä–æ–¥–µ {user}, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª–∏
    clean = re.sub(r"\{[^}]+\}", "value", text)
    # –£–±–∏—Ä–∞–µ–º –±—É–∫–≤–∞–ª—å–Ω—ã–µ escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ –ª–∏—Ç–µ—Ä–∞–ª–∞:
    # –∏—â–µ–º –û–î–ò–ù –æ–±—Ä–∞—Ç–Ω—ã–π —Å–ª–µ—à + n/r/t –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
    clean = re.sub(r"\\[nrtbfv0]", " ", clean)
    # –¢–∞–∫–∂–µ —É–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–µ—à–∏ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    clean = re.sub(r"\\", " ", clean)
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞, –≤–∫–ª—é—á–∞—è —ë/–Å
    words = re.findall(r"[–∞-—è–ê-–Ø—ë–Åa-zA-Z0-9]+", clean)
    translated = [translate_word(w) for w in words]
    slug = "_".join(translated).strip("_")
    slug = re.sub(r"_+", "_", slug)
    slug = slug[:60] or "text"
    base = slug
    counter = 0
    final = base
    while final in generated_keys:
        counter += 1
        final = f"{base}_{counter}"
    generated_keys.add(final)
    return final

def has_cyrillic(s: str) -> bool:
    return bool(re.search(r'[–∞-—è–ê-–Ø]', s))

def load_lexicon() -> Dict:
    if not os.path.exists(LEXICON_OUTPUT_FILE):
        return {}
    with open(LEXICON_OUTPUT_FILE, "r", encoding="utf-8") as f:
        code = f.read()
    try:
        import ast
        tree = ast.parse(code)
        for node in ast.walk(tree):
            if (isinstance(node, ast.Assign) and
                len(node.targets) == 1 and
                isinstance(node.targets[0], ast.Name) and
                node.targets[0].id == "LEXICON_RU"):
                d = ast.literal_eval(node.value)
                return d if isinstance(d, dict) else {}
    except:
        pass
    return {}

def save_lexicon(lexicon: Dict):
    os.makedirs(os.path.dirname(LEXICON_OUTPUT_FILE), exist_ok=True)
    with open(LEXICON_OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("# AUTO-GENERATED ‚Äî do not edit\n\nLEXICON_RU = {\n")
        for mod in sorted(lexicon):
            f.write(f'    "{mod}": {{\n')
            for k in sorted(lexicon[mod]):
                f.write(f'        "{k}": {repr(lexicon[mod][k])},\n')
            f.write("    },\n")
        f.write("}\n")

def extract_string_literal(lines: List[str], start_line: int, start_col: int) -> Optional[Tuple[str, int, int, bool, str]]:
    line = lines[start_line]
    pos = start_col

    prefix = ""
    while pos < len(line) and line[pos] in "fFrR":
        prefix += line[pos]
        pos += 1
    is_fstring = any(c in "fF" for c in prefix)

    if pos >= len(line):
        return None

    if line[pos:pos+3] in ('"""', "'''"):
        quotes = line[pos:pos+3]
        body_start = pos + 3
        current = line[body_start:]
        if quotes in current:
            end_idx = current.find(quotes)
            body = current[:end_idx]
            end_col = body_start + end_idx + 3
            full_literal = line[start_col:end_col]
            return body, start_line, start_line, is_fstring, full_literal
        else:
            body_lines = [current]
            i = start_line + 1
            while i < len(lines):
                if quotes in lines[i]:
                    end_idx = lines[i].find(quotes)
                    body_lines.append(lines[i][:end_idx])
                    body = "\n".join(body_lines)
                    full_lines = [line[start_col:]] + lines[start_line+1:i+1]
                    last_part = full_lines[-1]
                    end_quote_pos = last_part.find(quotes)
                    if end_quote_pos != -1:
                        full_literal = "".join(full_lines[:-1]) + last_part[:end_quote_pos + 3]
                    else:
                        full_literal = "".join(full_lines)
                    return body, start_line, i, is_fstring, full_literal
                else:
                    body_lines.append(lines[i].rstrip('\n'))
                    i += 1
            return None

    elif line[pos] in ('"', "'"):
        quote = line[pos]
        pos += 1
        body = ""
        escaped = False
        start_pos = start_col
        while pos < len(line):
            ch = line[pos]
            if escaped:
                body += ch
                escaped = False
            elif ch == '\\':
                body += ch
                escaped = True
            elif ch == quote:
                end_col = pos + 1
                full_literal = line[start_pos:end_col]
                return body, start_line, start_line, is_fstring, full_literal
            else:
                body += ch
            pos += 1
        return None

    else:
        return None

def is_simple_placeholder(expr: str) -> bool:
    return bool(re.fullmatch(r"[a-zA-Z_][a-zA-Z0-9_]*", expr.strip()))

def extract_placeholders(body: str) -> Tuple[bool, List[str]]:
    all_expr = re.findall(r"(?<!\{)\{([^}]*)\}(?!\})", body)
    simple_vars = []
    for expr in all_expr:
        if is_simple_placeholder(expr):
            simple_vars.append(expr.strip())
        else:
            return False, []
    return True, simple_vars

def is_in_valid_context(lines: List[str], line_idx: int, col: int) -> bool:
    current_line = lines[line_idx]

    # –ü—Ä–∞–≤–∏–ª–æ 1: –µ—Å—Ç—å '=' –ø–µ—Ä–µ–¥ –ª–∏—Ç–µ—Ä–∞–ª–æ–º –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ?
    before_literal = current_line[:col].rstrip()
    if '=' in before_literal:
        last_eq = before_literal.rfind('=')
        if last_eq == 0 or before_literal[last_eq - 1] not in ('!', '<', '>', '='):
            return True

    # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é '(' –Ω–∞ —Ç–µ–∫—É—â–µ–π –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–µ
    open_paren_line = -1
    open_paren_col = -1

    for j in range(col - 1, -1, -1):
        if current_line[j] == '(':
            open_paren_line = line_idx
            open_paren_col = j
            break

    if open_paren_line == -1 and line_idx > 0:
        prev_line = lines[line_idx - 1].rstrip()
        if prev_line.endswith('('):
            open_paren_line = line_idx - 1
            open_paren_col = len(prev_line) - 1

    if open_paren_line == -1:
        return False

    line_with_paren = lines[open_paren_line]
    before_paren = line_with_paren[:open_paren_col].rstrip()

    if not before_paren:
        return False

    # –ü—Ä–∞–≤–∏–ª–æ 2: –ø–µ—Ä–µ–¥ '(' –µ—Å—Ç—å '='?
    if '=' in before_paren:
        last_eq = before_paren.rfind('=')
        if last_eq == 0 or before_paren[last_eq - 1] not in ('!', '<', '>', '='):
            return True

    # –ü—Ä–∞–≤–∏–ª–æ 3: –ø–µ—Ä–µ–¥ '(' ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞?
    words = re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*', before_paren)
    if words:
        func_name = words[-1]
        if func_name in SEND_FUNCTIONS:
            return True

    return False

def main():
    global generated_keys
    generated_keys = set()

    if not os.path.exists(INPUT_FILE):
        print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return

    shutil.copy2(INPUT_FILE, BACKUP_FILE)
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()

    lexicon = load_lexicon()
    if MODULE_PREFIX not in lexicon:
        lexicon[MODULE_PREFIX] = {}

    replacements = []

    i = 0
    while i < len(lines):
        line = lines[i]
        lineno = i + 1
        if lineno < START_LINE:
            i += 1
            continue

        stripped = line.strip()
        if not stripped or stripped.startswith('#'):
            i += 1
            continue

        comment_pos = line.find('#')
        j = 0
        while j < len(line):
            if comment_pos != -1 and j >= comment_pos:
                break  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –∫–∞–≤—ã—á–µ–∫
            if j < len(line) and line[j] in ('"', "'"):
                quote_start = j
            elif j + 2 < len(line) and line[j:j+3] in ('"""', "'''"):
                quote_start = j
            else:
                j += 1
                continue

            # –ò—â–µ–º f/F –ø–µ—Ä–µ–¥ –∫–∞–≤—ã—á–∫–æ–π
            literal_start = quote_start
            k = quote_start - 1
            while k >= 0 and line[k] in "fFrR":
                k -= 1
            if k + 1 < quote_start:
                literal_start = k + 1

            result = extract_string_literal(lines, i, literal_start)
            if result:
                body, start_line, end_line, is_fstring, full_literal = result
                if has_cyrillic(body):
                    if is_in_valid_context(lines, i, literal_start):
                        if is_fstring:
                            is_simple, placeholders = extract_placeholders(body)
                            slug_body = re.sub(r"(?<!\{)\{[^}]*\}(?!\})", "value", body)
                            key = smart_slugify(slug_body)
                            full_key = f"{MODULE_PREFIX}.{key}"
                            if key not in lexicon[MODULE_PREFIX]:
                                lexicon[MODULE_PREFIX][key] = body

                            base_call = f'get_text("{full_key}", lang)'
                            if is_simple and placeholders:
                                fmt_args = ", ".join(f"{v}={v}" for v in sorted(set(placeholders)))
                                replacement = f"{base_call}.format({fmt_args})"
                            else:
                                replacement = f"{base_call}.format(/*** NEED MANUAL FIX ***/)"
                        else:
                            key = smart_slugify(body)
                            full_key = f"{MODULE_PREFIX}.{key}"
                            if key not in lexicon[MODULE_PREFIX]:
                                lexicon[MODULE_PREFIX][key] = body
                            replacement = f'get_text("{full_key}", lang)'

                        replacements.append((
                            start_line, end_line, full_literal, replacement, body
                        ))
                        j = literal_start + len(full_literal)
                        continue

            j += 1
        i += 1

    # === –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ó–ê–ú–ï–ù–´ ===
    new_lines = lines[:]
    for start_line, end_line, full_literal, replacement, _ in reversed(replacements):
        # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –±–ª–æ–∫ —Å—Ç—Ä–æ–∫, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏—Ç–µ—Ä–∞–ª
        block_lines = lines[start_line:end_line + 1]
        block_text = "".join(block_lines)

        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ª–∏—Ç–µ—Ä–∞–ª–∞ –≤ –±–ª–æ–∫–µ
        idx = block_text.find(full_literal)
        if idx == -1:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            continue

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—Ä–µ—Ñ–∏–∫—Å, –ª–∏—Ç–µ—Ä–∞–ª, —Å—É—Ñ—Ñ–∏–∫—Å
        prefix = block_text[:idx]
        suffix = block_text[idx + len(full_literal):]

        # –£–¥–∞–ª—è–µ–º 'f' –∏–ª–∏ 'F' –∏–∑ –∫–æ–Ω—Ü–∞ prefix
        if prefix.endswith('f') or prefix.endswith('F'):
            prefix = prefix[:-1]

        # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–æ–¥–∞
        new_code_line = prefix + replacement + suffix

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ä–∏–≥–∏–Ω–∞–ª
        commented_block = []
        for k in range(start_line, end_line + 1):
            orig_line = lines[k]
            stripped_orig = orig_line.rstrip()
            if stripped_orig and not stripped_orig.lstrip().startswith('#'):
                commented_block.append("# " + stripped_orig + "\n")
            else:
                commented_block.append(stripped_orig + "\n")

        # –ó–∞–º–µ–Ω—è–µ–º –±–ª–æ–∫: —Å–Ω–∞—á–∞–ª–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –ø–æ—Ç–æ–º –Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
        replacement_block = commented_block + [new_code_line + "\n"]

        new_lines = (
            new_lines[:start_line] +
            replacement_block +
            new_lines[end_line + 1:]
        )

    with open(INPUT_FILE, "w", encoding="utf-8") as f:
        f.writelines(new_lines)

    save_lexicon(lexicon)
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(replacements)} —Å—Ç—Ä–æ–∫.")

if __name__ == "__main__":

    main()


